#!/usr/bin/env python3
"""
Ch∆∞∆°ng tr√¨nh chu·∫©n h√≥a file BTC CSV t·ª´ 2018-2025 th√†nh format cho TimeXer
"""

import pandas as pd
import numpy as np
from datetime import datetime
import os

def normalize_btc_csv(input_file, output_file, coin_id=9):
    """
    Chu·∫©n h√≥a file BTC CSV th√†nh format TimeXer
    
    Args:
        input_file: ƒê∆∞·ªùng d·∫´n file BTC CSV g·ªëc
        output_file: ƒê∆∞·ªùng d·∫´n file CSV ƒë·∫ßu ra
        coin_id: ID c·ªßa coin (m·∫∑c ƒë·ªãnh 9 cho BTC)
    """
    
    print(f"üîÑ Processing BTC data from {input_file}")
    
    # ƒê·ªçc file CSV g·ªëc
    df = pd.read_csv(input_file)
    print(f"üìä Original data shape: {df.shape}")
    print(f"üìù Original columns: {list(df.columns)}")
    
    # Hi·ªÉn th·ªã v√†i d√≤ng ƒë·∫ßu
    print("\nüìã Sample original data:")
    print(df.head(3))
    
    # T·∫°o DataFrame m·ªõi v·ªõi format chu·∫©n cho TimeXer
    normalized_df = pd.DataFrame()
    
    # 1. X·ª≠ l√Ω Date column
    # Chuy·ªÉn 'Open time' th√†nh datetime v√† format l·∫°i
    df['Open time'] = pd.to_datetime(df['Open time'])
    normalized_df['date'] = df['Open time'].dt.strftime('%Y-%m-%d %H:%M:%S')
    
    # 2. Map c√°c columns OHLCV
    column_mapping = {
        'High': 'High',
        'Low': 'Low', 
        'Open': 'Open',
        'Close': 'Close',
        'Volume': 'Volume'
    }
    
    for new_col, old_col in column_mapping.items():
        if old_col in df.columns:
            normalized_df[new_col] = df[old_col].astype(float)
        else:
            print(f"‚ö†Ô∏è  Column '{old_col}' not found, using default values")
            normalized_df[new_col] = 1.0
    
    # 3. T√≠nh Market Cap (∆∞·ªõc t√≠nh = Close * Volume)
    # V√¨ kh√¥ng c√≥ market cap th·ª±c, ta ∆∞·ªõc t√≠nh ho·∫∑c d√πng gi√° tr·ªã m·∫∑c ƒë·ªãnh
    normalized_df['Marketcap'] = normalized_df['Close'] * normalized_df['Volume'] * 1000  # Scale up
    
    # 4. Th√™m Coin_ID
    normalized_df['Coin_ID'] = coin_id
    
    # 5. S·∫Øp x·∫øp l·∫°i th·ª© t·ª± columns theo format TimeXer
    final_columns = ['date', 'High', 'Low', 'Open', 'Volume', 'Marketcap', 'Coin_ID', 'Close']
    normalized_df = normalized_df[final_columns]
    
    # 6. X·ª≠ l√Ω missing values v√† outliers
    print(f"\nüîç Checking data quality...")
    print(f"   Missing values per column:")
    missing_info = normalized_df.isnull().sum()
    for col, missing in missing_info.items():
        if missing > 0:
            print(f"      {col}: {missing}")
    
    # Fill missing values
    numeric_columns = ['High', 'Low', 'Open', 'Close', 'Volume', 'Marketcap']
    for col in numeric_columns:
        if normalized_df[col].isnull().any():
            normalized_df[col] = normalized_df[col].fillna(method='ffill').fillna(method='bfill')
    
    # 7. Ki·ªÉm tra v√† s·ª≠a logic errors (High < Low, etc.)
    print(f"\nüîß Fixing data logic errors...")
    
    # ƒê·∫£m b·∫£o High >= Low
    mask = normalized_df['High'] < normalized_df['Low']
    if mask.any():
        print(f"   Fixed {mask.sum()} cases where High < Low")
        # Swap High and Low
        normalized_df.loc[mask, ['High', 'Low']] = normalized_df.loc[mask, ['Low', 'High']].values
    
    # ƒê·∫£m b·∫£o High >= Open, Close v√† Low <= Open, Close  
    normalized_df['High'] = normalized_df[['High', 'Open', 'Close']].max(axis=1)
    normalized_df['Low'] = normalized_df[['Low', 'Open', 'Close']].min(axis=1)
    
    # 8. Remove duplicates n·∫øu c√≥
    original_len = len(normalized_df)
    normalized_df = normalized_df.drop_duplicates(subset=['date'])
    if len(normalized_df) < original_len:
        print(f"   Removed {original_len - len(normalized_df)} duplicate dates")
    
    # 9. Sort by date
    normalized_df = normalized_df.sort_values('date').reset_index(drop=True)
    
    # 10. Th·ªëng k√™ cu·ªëi
    print(f"\nüìä Normalized data statistics:")
    print(f"   Final shape: {normalized_df.shape}")
    print(f"   Date range: {normalized_df['date'].min()} to {normalized_df['date'].max()}")
    print(f"   Close price range: ${normalized_df['Close'].min():.2f} - ${normalized_df['Close'].max():.2f}")
    print(f"   Average daily volume: {normalized_df['Volume'].mean():.2f}")
    
    print(f"\nüìã Sample normalized data:")
    print(normalized_df.head())
    print("...")
    print(normalized_df.tail())
    
    # 11. L∆∞u file
    normalized_df.to_csv(output_file, index=False)
    print(f"\n‚úÖ Normalized data saved to: {output_file}")
    
    return normalized_df


def create_prediction_sample(normalized_file, sample_days=168, output_sample='btc_168_days_sample.csv'):
    """
    T·∫°o file m·∫´u 168 ng√†y cu·ªëi ƒë·ªÉ d·ª± ƒëo√°n
    """
    df = pd.read_csv(normalized_file)
    
    # L·∫•y 168 ng√†y cu·ªëi
    sample_df = df.tail(sample_days).copy().reset_index(drop=True)
    
    # L∆∞u sample
    sample_df.to_csv(output_sample, index=False)
    
    print(f"üìÑ Created prediction sample: {output_sample}")
    print(f"   Sample shape: {sample_df.shape}")
    print(f"   Date range: {sample_df['date'].min()} to {sample_df['date'].max()}")
    print(f"   Last close price: ${sample_df['Close'].iloc[-1]:.2f}")
    
    return sample_df


def main():
    """Main function"""
    print("üöÄ BTC Data Normalizer for TimeXer")
    print("="*50)
    
    # Input v√† output files
    input_file = 'btc_1d_data_2018_to_2025.csv'
    output_file = 'btc_normalized_for_timexer.csv'
    sample_file = 'btc_168_days_sample.csv'
    
    # Ki·ªÉm tra file input
    if not os.path.exists(input_file):
        print(f"‚ùå File kh√¥ng t·ªìn t·∫°i: {input_file}")
        print("H√£y ƒë·∫£m b·∫£o file BTC CSV c√≥ t√™n 'btc_1d_data_2018_to_2025.csv'")
        return
    
    try:
        # 1. Chu·∫©n h√≥a d·ªØ li·ªáu
        normalized_df = normalize_btc_csv(input_file, output_file, coin_id=9)
        
        # 2. T·∫°o sample 168 ng√†y ƒë·ªÉ d·ª± ƒëo√°n
        sample_df = create_prediction_sample(output_file, 168, sample_file)
        
        print(f"\nüéâ Ho√†n th√†nh!")
        print(f"üìÅ Files ƒë∆∞·ª£c t·∫°o:")
        print(f"   1. {output_file} - Full normalized data ({len(normalized_df)} rows)")
        print(f"   2. {sample_file} - 168 days sample for prediction")
        
        print(f"\nüìñ C√°ch s·ª≠ d·ª•ng:")
        print(f"   1. ƒê·ªÉ train model m·ªõi: s·ª≠ d·ª•ng {output_file}")
        print(f"   2. ƒê·ªÉ d·ª± ƒëo√°n v·ªõi model ƒë√£ train:")
        print(f"      python3 predict_new_data.py {sample_file}")
        
    except Exception as e:
        print(f"‚ùå L·ªói: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()
