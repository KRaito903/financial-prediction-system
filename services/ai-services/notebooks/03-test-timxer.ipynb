{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "58b31da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Setup and Imports\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "# --- Thêm đường dẫn project vào hệ thống ---\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "\n",
    "\n",
    "# Cấu hình để Pytorch hoạt động tốt với một số môi trường\n",
    "os.environ[\"PYTORCH_ENABLE_MPS_FALLBACK\"] = \"1\"\n",
    "curr_dir = os.getcwd()\n",
    "path = os.path.join(curr_dir, \"..\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67784208",
   "metadata": {},
   "source": [
    "# Fecth data USD + ETH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb135e9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/quockhoile/Desktop/DaiHoc/KT/Project/AI-Predict/financial-prediction-system/services/ai-services/src/utils/standardizer.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['timestamp'] = pd.to_datetime(df['timestamp'], unit=\"ms\")\n",
      "/Users/quockhoile/Desktop/DaiHoc/KT/Project/AI-Predict/financial-prediction-system/services/ai-services/src/utils/standardizer.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['timestamp'] = pd.to_datetime(df['timestamp'], unit=\"ms\")\n"
     ]
    }
   ],
   "source": [
    "from src.data.fecther_factory import FetcherFactory\n",
    "import dotenv\n",
    "from src.data.saver_factory import SaverFactory\n",
    "\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "api_key = os.getenv(\"API-Key\")\n",
    "api_secret = os.getenv(\"Secret-Key\")\n",
    "\n",
    "fetcher = FetcherFactory.create_data_fetcher(\"binance\", api_key=api_key, api_secret=api_secret)\n",
    "\n",
    "data_btc = fetcher.fetch_data(\n",
    "    symbol=\"BTCUSDT\",\n",
    "    interval=\"1d\",\n",
    "    start_str=\"2025-01-01\"\n",
    ")\n",
    "\n",
    "data_eth = fetcher.fetch_data(\n",
    "    symbol=\"ETHUSDT\",\n",
    "    interval=\"1d\",\n",
    "    start_str=\"2025-01-01\"\n",
    ")\n",
    "\n",
    "saver = SaverFactory.create_data_saver(\"csv\")\n",
    "\n",
    "\n",
    "saver.save_data(data_btc, file_path=f\"{path}/data/raw/day/BTCUSDT.csv\")\n",
    "saver.save_data(data_eth, file_path=f\"{path}/data/raw/day/ETHUSDT.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aa45f9d",
   "metadata": {},
   "source": [
    "# Load data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6229460e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                open      high       low     close    volume   symbol  \\\n",
      "timestamp                                                               \n",
      "2025-01-14  0.470736  0.498260  0.568333  0.564715 -0.744934  BTCUSDT   \n",
      "2025-01-15  0.576382  0.750704  0.642522  0.833228 -0.486008  BTCUSDT   \n",
      "2025-01-16  0.847186  0.735632  0.739161  0.662687 -0.465569  BTCUSDT   \n",
      "2025-01-17  0.675182  0.811140  0.790559  0.859510 -0.329400  BTCUSDT   \n",
      "2025-01-18  0.873717  0.774706  0.692186  0.662282  0.003757  BTCUSDT   \n",
      "...              ...       ...       ...       ...       ...      ...   \n",
      "2025-08-30  1.936577  1.846000  1.951122  1.929413 -0.842851  ETHUSDT   \n",
      "2025-08-31  1.952786  1.942358  2.092181  1.950964 -0.795989  ETHUSDT   \n",
      "2025-09-01  1.974522  1.934648  1.894187  1.859042 -0.342998  ETHUSDT   \n",
      "2025-09-02  1.881812  1.847360  1.951916  1.873307 -0.311958  ETHUSDT   \n",
      "2025-09-03  1.896187  1.933253  1.982931  2.036561 -0.546996  ETHUSDT   \n",
      "\n",
      "            sentiment_score  close_lag_1  close_lag_7    ema_10    ema_20  \\\n",
      "timestamp                                                                   \n",
      "2025-01-14              0.0     0.470738     0.834681  0.720497  0.868977   \n",
      "2025-01-15              0.0     0.576384     0.766825  0.755351  0.882625   \n",
      "2025-01-16              0.0     0.847200     0.631049  0.750922  0.876345   \n",
      "2025-01-17              0.0     0.675196     0.691143  0.785322  0.892162   \n",
      "2025-01-18              0.0     0.873707     0.710977  0.775366  0.884930   \n",
      "...                     ...          ...          ...       ...       ...   \n",
      "2025-08-30              0.0     1.936580     2.589612  2.189780  2.277698   \n",
      "2025-08-31              0.0     1.952789     2.591810  2.173424  2.279266   \n",
      "2025-09-01              0.0     1.974524     2.084370  2.142284  2.270644   \n",
      "2025-09-02              0.0     1.881815     2.366309  2.119561  2.264402   \n",
      "2025-09-03              0.0     1.896201     2.248333  2.132509  2.276585   \n",
      "\n",
      "            volatility_10     rsi_14  day_of_week   day_sin   day_cos  \n",
      "timestamp                                                              \n",
      "2025-01-14    2714.238922  54.182724            1  0.781831  0.623490  \n",
      "2025-01-15    2989.433771  65.051060            2  0.974928 -0.222521  \n",
      "2025-01-16    2537.736889  62.966884            3  0.433884 -0.900969  \n",
      "2025-01-17    3608.518880  70.992879            4 -0.433884 -0.900969  \n",
      "2025-01-18    4306.797050  71.764243            5 -0.974928 -0.222521  \n",
      "...                   ...        ...          ...       ...       ...  \n",
      "2025-08-30     208.428209  52.320869            5 -0.974928 -0.222521  \n",
      "2025-08-31     186.480081  52.781988            6 -0.781831  0.623490  \n",
      "2025-09-01     171.018889  50.536925            0  0.000000  1.000000  \n",
      "2025-09-02     147.125456  50.886038            1  0.781831  0.623490  \n",
      "2025-09-03      93.471021  54.816677            2  0.974928 -0.222521  \n",
      "\n",
      "[466 rows x 16 columns]\n"
     ]
    }
   ],
   "source": [
    "from src.data.loader.data_loader_service import DataLoaderService\n",
    "from src.data.loader.csv_loader import CSVLoader\n",
    "from src.features.feature_engineer import FeatureEngineer\n",
    "from src.utils.normalizer import Normalizer\n",
    "\n",
    "repository_data = CSVLoader(file_path=path+\"/data/raw/day\")\n",
    "data_loader = DataLoaderService(repository_data)\n",
    "\n",
    "\n",
    "raw_data = data_loader.load_data()\n",
    "\n",
    "fe = FeatureEngineer(lags=[1,7], emas=[10,20], add_volatility=True, add_rsi=True, add_datetime=True)\n",
    "\n",
    "data_fe = fe.transform(raw_data)\n",
    "\n",
    "saver.save_data(data_fe, file_path=f\"{path}/data/processed/data.csv\")\n",
    "\n",
    "\n",
    "numeric_cols = [\"open\", \"high\", \"low\", \"close\", \"volume\", \n",
    "                \"close_lag_1\", \"close_lag_7\", \"ema_10\", \"ema_20\"]\n",
    "\n",
    "normalizer = Normalizer(\"standard\", per_symbol=True, columns=numeric_cols)\n",
    "data_normalized = normalizer.fit_transform(data_fe)\n",
    "\n",
    "\n",
    "print(data_normalized)\n",
    "\n",
    "saver.save_data(data_normalized, file_path=f\"{path}/data/processed/data_normalized.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "419b3255",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# from pytorch_forecasting import TimeSeriesDataSet\n",
    "\n",
    "# # reset index để timestamp trở lại làm cột\n",
    "# df = df.reset_index()\n",
    "\n",
    "# # tạo time_idx từ timestamp (số ngày kể từ mốc đầu tiên)\n",
    "# df[\"time_idx\"] = (df[\"timestamp\"] - df[\"timestamp\"].min()).dt.days\n",
    "\n",
    "# # xác định cutoff cho tập train\n",
    "# training_cutoff = df[\"time_idx\"].max() - 30  # 30 ngày cuối để test\n",
    "\n",
    "# # dataset cho training\n",
    "# training = TimeSeriesDataSet(\n",
    "#     df[lambda x: x.time_idx <= training_cutoff],\n",
    "#     time_idx=\"time_idx\",\n",
    "#     target=\"close\",                 # target để dự đoán\n",
    "#     group_ids=[\"symbol\"],           # mỗi coin là 1 group\n",
    "#     min_encoder_length=24,          # số bước nhìn lại\n",
    "#     max_encoder_length=48,          # encoder context\n",
    "#     min_prediction_length=1,\n",
    "#     max_prediction_length=30,       # dự đoán 30 bước tới\n",
    "#     time_varying_known_reals=[\"hour\", \"dayofweek\", \"weekofyear\"],\n",
    "#     time_varying_unknown_reals=[\n",
    "#         \"open\", \"high\", \"low\", \"close\", \"volume\",\n",
    "#         \"sentiment_score\", \"close_lag_1\", \"close_lag_2\",\n",
    "#         \"close_lag_3\", \"close_lag_24\", \"EMA_12\", \"EMA_26\",\n",
    "#         \"SMA_50\", \"RSI_14\", \"BBM_20_2\", \"BBP_20_2\",\n",
    "#         \"MACD_12_26_9\", \"MACDs_12_26_9\", \"MACDh_12_26_9\"\n",
    "#     ],\n",
    "#     target_normalizer=None,  # có thể dùng GroupNormalizer nếu nhiều symbol\n",
    "#     add_relative_time_idx=True,\n",
    "#     add_target_scales=True,\n",
    "#     add_encoder_length=True,\n",
    "# )\n",
    "\n",
    "# # dataset cho validation\n",
    "# validation = TimeSeriesDataSet.from_dataset(training, df, min_prediction_idx=training_cutoff + 1)\n",
    "\n",
    "# # tạo DataLoader\n",
    "# from torch.utils.data import DataLoader\n",
    "\n",
    "# batch_size = 64\n",
    "# train_dataloader = DataLoader(training, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "# val_dataloader = DataLoader(validation, batch_size=batch_size, shuffle=False, num_workers=4)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
